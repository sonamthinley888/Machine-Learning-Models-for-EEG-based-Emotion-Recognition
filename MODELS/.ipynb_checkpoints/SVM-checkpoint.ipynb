{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9d8982-662c-4fa5-9117-4e79f00625a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "import ast\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import mne\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sb \n",
    "import matplotlib.pyplot as mp \n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0230cc32-21e0-4b06-90ac-e2ebc02a4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScaler(df):\n",
    "    scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "    scaled_df = scaler.fit_transform(df)\n",
    "    return scaled_df\n",
    "\n",
    "def standardScaler(df):\n",
    "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "    scaled_df = scaler.fit_transform(df)\n",
    "    return scaled_df\n",
    "\n",
    "def pcaScaler(df):\n",
    "    pca = PCA(n_components = 2).fit(df)\n",
    "    df_transformed = pca.transform(pca)\n",
    "    return df_transformed\n",
    "\n",
    "def preprocess_inputs(df_2):\n",
    "    df = df_2.copy()\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    #df['emotion'] = df['emotion'].replace(label_mapping)\n",
    "    df['emotion']= label_encoder.fit_transform(df['emotion']) \n",
    "  \n",
    "    df['emotion'].unique() \n",
    "    \n",
    "    y = df['emotion'].copy()\n",
    "    X = df.drop(['emotion', 'subject','session'], axis=1).copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1, stratify=y)\n",
    "\n",
    "    return X,y,  X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719127a2-f567-4b31-bee1-858f9434bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "# feature_extraction_v9 has Only PSD V9.1 had PSD and DE for Session 1\n",
    "# v10 is ALL Sessions with both PSD and DE\n",
    "# V11 is Session 1 and Session 2 with only PSD\n",
    "# V11.1 is Session 1 and Session 2 with PSD and DE\n",
    "df_2 = pd.read_csv(\"feature_extracted_200/feature_extracted_v12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ec01b04-aace-4d8d-84bf-a61f9de92c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 313)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76ef7990-20f5-4144-b90e-3f8ffec92a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>emotion</th>\n",
       "      <th>delta_ch_1</th>\n",
       "      <th>delta_ch_2</th>\n",
       "      <th>delta_ch_3</th>\n",
       "      <th>delta_ch_4</th>\n",
       "      <th>delta_ch_5</th>\n",
       "      <th>delta_ch_6</th>\n",
       "      <th>delta_ch_7</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_ch_53</th>\n",
       "      <th>gamma_ch_54</th>\n",
       "      <th>gamma_ch_55</th>\n",
       "      <th>gamma_ch_56</th>\n",
       "      <th>gamma_ch_57</th>\n",
       "      <th>gamma_ch_58</th>\n",
       "      <th>gamma_ch_59</th>\n",
       "      <th>gamma_ch_60</th>\n",
       "      <th>gamma_ch_61</th>\n",
       "      <th>gamma_ch_62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>0.011459</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.030851</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035127</td>\n",
       "      <td>0.031020</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022806</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.016132</td>\n",
       "      <td>0.023095</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.018203</td>\n",
       "      <td>0.026965</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030469</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12656</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.036794</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12657</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.013085</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.029153</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12660 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session  subject  emotion  delta_ch_1  delta_ch_2  delta_ch_3  \\\n",
       "0            1        0        1    0.007224    0.008040    0.011459   \n",
       "1            1        0        1    0.033514    0.033033    0.033115   \n",
       "2            1        0        1    0.035127    0.031020    0.024701   \n",
       "3            1        0        1    0.022806    0.027254    0.027382   \n",
       "4            1        0        1    0.032432    0.040247    0.038222   \n",
       "...        ...      ...      ...         ...         ...         ...   \n",
       "12655        1       14        0    0.030469    0.029354    0.028572   \n",
       "12656        1       14        3    0.033316    0.036794    0.036194   \n",
       "12657        1       14        0    0.023092    0.026631    0.026865   \n",
       "12658        1       14        1    0.010104    0.009597    0.008523   \n",
       "12659        1       14        2    0.009911    0.006146    0.011478   \n",
       "\n",
       "       delta_ch_4  delta_ch_5  delta_ch_6  delta_ch_7  ...  gamma_ch_53  \\\n",
       "0        0.003016    0.003143    0.008769    0.002074  ...     0.000065   \n",
       "1        0.018684    0.030851    0.018572    0.017610  ...     0.000175   \n",
       "2        0.014744    0.019542    0.012554    0.008293  ...     0.000137   \n",
       "3        0.016132    0.023095    0.016576    0.013758  ...     0.000181   \n",
       "4        0.018203    0.026965    0.019068    0.013009  ...     0.000674   \n",
       "...           ...         ...         ...         ...  ...          ...   \n",
       "12655    0.019778    0.017288    0.025797    0.016761  ...     0.000120   \n",
       "12656    0.028411    0.036138    0.012875    0.012220  ...     0.000146   \n",
       "12657    0.013849    0.016016    0.027036    0.018801  ...     0.000236   \n",
       "12658    0.008035    0.008583    0.008840    0.008316  ...     0.000743   \n",
       "12659    0.013085    0.010414    0.029153    0.021779  ...     0.000216   \n",
       "\n",
       "       gamma_ch_54  gamma_ch_55  gamma_ch_56  gamma_ch_57  gamma_ch_58  \\\n",
       "0         0.000014     0.000057     0.000028     0.000050     0.000070   \n",
       "1         0.000149     0.000249     0.000384     0.000428     0.000176   \n",
       "2         0.000278     0.000538     0.000541     0.000618     0.000139   \n",
       "3         0.000144     0.000230     0.000273     0.000377     0.000179   \n",
       "4         0.000693     0.000365     0.000548     0.000428     0.000677   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "12655     0.000099     0.000088     0.000083     0.000085     0.000116   \n",
       "12656     0.000280     0.000997     0.000973     0.000961     0.000157   \n",
       "12657     0.000233     0.000190     0.000186     0.000191     0.000239   \n",
       "12658     0.000769     0.001140     0.001139     0.001432     0.000732   \n",
       "12659     0.000345     0.001014     0.001002     0.000949     0.000207   \n",
       "\n",
       "       gamma_ch_59  gamma_ch_60  gamma_ch_61  gamma_ch_62  \n",
       "0         0.000067     0.000121     0.000055     0.000151  \n",
       "1         0.000182     0.000149     0.000126     0.000168  \n",
       "2         0.000140     0.000342     0.000932     0.000311  \n",
       "3         0.000178     0.000158     0.000235     0.000429  \n",
       "4         0.000681     0.000722     0.000692     0.000971  \n",
       "...            ...          ...          ...          ...  \n",
       "12655     0.000119     0.000102     0.000084     0.000082  \n",
       "12656     0.000162     0.000289     0.000972     0.000999  \n",
       "12657     0.000237     0.000239     0.000182     0.000181  \n",
       "12658     0.000737     0.000784     0.001138     0.001114  \n",
       "12659     0.000203     0.000367     0.001029     0.001050  \n",
       "\n",
       "[12660 rows x 313 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fe962e4-ea30-49ce-88fc-f6c032558921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "1    3870\n",
       "0    3240\n",
       "3    2850\n",
       "2    2700\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f6667b-e52c-4657-a260-c5a551cc5d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session', 'subject', 'emotion', 'delta_ch_1', 'delta_ch_2',\n",
       "       'delta_ch_3', 'delta_ch_4', 'delta_ch_5', 'delta_ch_6', 'delta_ch_7',\n",
       "       ...\n",
       "       'gamma_ch_53', 'gamma_ch_54', 'gamma_ch_55', 'gamma_ch_56',\n",
       "       'gamma_ch_57', 'gamma_ch_58', 'gamma_ch_59', 'gamma_ch_60',\n",
       "       'gamma_ch_61', 'gamma_ch_62'],\n",
       "      dtype='object', length=313)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af9fa343-f8a1-4fe8-bafb-1b9ceeb8976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_mapping = {'NEUTRAL': 0, 'SAD': 1, 'FEAR': 2, 'HAPPY':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a528470-7c1f-416d-9b10-6b0f4e99b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = preprocess_inputs(df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d5efef2-8687-474b-86aa-af0f4416e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10128, 310)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d7e70ad-3985-4ddb-8c63-d5b2e0c03250",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = standardScaler(X_train)\n",
    "X_test = standardScaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09be81b9-ae66-4d4b-b8e8-31486d39fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = minMaxScaler(X_train)\n",
    "X_test= minMaxScaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30c76442-9e4f-4c96-8af8-df4fe2e8cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_ch_1</th>\n",
       "      <th>delta_ch_2</th>\n",
       "      <th>delta_ch_3</th>\n",
       "      <th>delta_ch_4</th>\n",
       "      <th>delta_ch_5</th>\n",
       "      <th>delta_ch_6</th>\n",
       "      <th>delta_ch_7</th>\n",
       "      <th>delta_ch_8</th>\n",
       "      <th>delta_ch_9</th>\n",
       "      <th>delta_ch_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_ch_53</th>\n",
       "      <th>gamma_ch_54</th>\n",
       "      <th>gamma_ch_55</th>\n",
       "      <th>gamma_ch_56</th>\n",
       "      <th>gamma_ch_57</th>\n",
       "      <th>gamma_ch_58</th>\n",
       "      <th>gamma_ch_59</th>\n",
       "      <th>gamma_ch_60</th>\n",
       "      <th>gamma_ch_61</th>\n",
       "      <th>gamma_ch_62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>0.153181</td>\n",
       "      <td>0.350419</td>\n",
       "      <td>0.498484</td>\n",
       "      <td>0.157720</td>\n",
       "      <td>0.486005</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>0.584575</td>\n",
       "      <td>0.576647</td>\n",
       "      <td>0.152469</td>\n",
       "      <td>0.239082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.050606</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>0.053185</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.025892</td>\n",
       "      <td>0.047060</td>\n",
       "      <td>0.069642</td>\n",
       "      <td>0.045041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>0.476661</td>\n",
       "      <td>0.571317</td>\n",
       "      <td>0.603340</td>\n",
       "      <td>0.387782</td>\n",
       "      <td>0.553797</td>\n",
       "      <td>0.785409</td>\n",
       "      <td>0.728427</td>\n",
       "      <td>0.727731</td>\n",
       "      <td>0.476403</td>\n",
       "      <td>0.483077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042385</td>\n",
       "      <td>0.046910</td>\n",
       "      <td>0.135830</td>\n",
       "      <td>0.154097</td>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.066408</td>\n",
       "      <td>0.092475</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>0.229695</td>\n",
       "      <td>0.115491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0.704278</td>\n",
       "      <td>0.578399</td>\n",
       "      <td>0.546968</td>\n",
       "      <td>0.714151</td>\n",
       "      <td>0.413070</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.708759</td>\n",
       "      <td>0.708311</td>\n",
       "      <td>0.567819</td>\n",
       "      <td>0.470531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049085</td>\n",
       "      <td>0.072504</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.083405</td>\n",
       "      <td>0.088006</td>\n",
       "      <td>0.055335</td>\n",
       "      <td>0.048416</td>\n",
       "      <td>0.064150</td>\n",
       "      <td>0.128891</td>\n",
       "      <td>0.082047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0.405527</td>\n",
       "      <td>0.545927</td>\n",
       "      <td>0.564149</td>\n",
       "      <td>0.436535</td>\n",
       "      <td>0.487349</td>\n",
       "      <td>0.182151</td>\n",
       "      <td>0.307276</td>\n",
       "      <td>0.482612</td>\n",
       "      <td>0.525807</td>\n",
       "      <td>0.439476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.639820</td>\n",
       "      <td>0.644632</td>\n",
       "      <td>0.633625</td>\n",
       "      <td>0.508083</td>\n",
       "      <td>0.550546</td>\n",
       "      <td>0.374616</td>\n",
       "      <td>0.458939</td>\n",
       "      <td>0.468819</td>\n",
       "      <td>0.465676</td>\n",
       "      <td>0.469366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>0.067957</td>\n",
       "      <td>0.052626</td>\n",
       "      <td>0.058225</td>\n",
       "      <td>0.069410</td>\n",
       "      <td>0.047011</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.057681</td>\n",
       "      <td>0.083602</td>\n",
       "      <td>0.132935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>0.244472</td>\n",
       "      <td>0.782263</td>\n",
       "      <td>0.833547</td>\n",
       "      <td>0.774767</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.530316</td>\n",
       "      <td>0.624453</td>\n",
       "      <td>0.608354</td>\n",
       "      <td>0.410154</td>\n",
       "      <td>0.589162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>0.022080</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.015182</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.014888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.198776</td>\n",
       "      <td>0.245048</td>\n",
       "      <td>0.174620</td>\n",
       "      <td>0.303401</td>\n",
       "      <td>0.376952</td>\n",
       "      <td>0.222133</td>\n",
       "      <td>0.338558</td>\n",
       "      <td>0.336561</td>\n",
       "      <td>0.334959</td>\n",
       "      <td>0.269705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176179</td>\n",
       "      <td>0.118855</td>\n",
       "      <td>0.179979</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.178276</td>\n",
       "      <td>0.179587</td>\n",
       "      <td>0.159779</td>\n",
       "      <td>0.158871</td>\n",
       "      <td>0.086228</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>0.210066</td>\n",
       "      <td>0.297961</td>\n",
       "      <td>0.367230</td>\n",
       "      <td>0.206470</td>\n",
       "      <td>0.464282</td>\n",
       "      <td>0.143529</td>\n",
       "      <td>0.133425</td>\n",
       "      <td>0.134979</td>\n",
       "      <td>0.401385</td>\n",
       "      <td>0.301186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096175</td>\n",
       "      <td>0.075173</td>\n",
       "      <td>0.109514</td>\n",
       "      <td>0.096575</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>0.135039</td>\n",
       "      <td>0.119026</td>\n",
       "      <td>0.083509</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>0.049063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>0.291022</td>\n",
       "      <td>0.328981</td>\n",
       "      <td>0.379860</td>\n",
       "      <td>0.393899</td>\n",
       "      <td>0.379593</td>\n",
       "      <td>0.487379</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.394238</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.281180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048904</td>\n",
       "      <td>0.050790</td>\n",
       "      <td>0.038233</td>\n",
       "      <td>0.066045</td>\n",
       "      <td>0.067044</td>\n",
       "      <td>0.153495</td>\n",
       "      <td>0.085527</td>\n",
       "      <td>0.093413</td>\n",
       "      <td>0.129107</td>\n",
       "      <td>0.113034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.769568</td>\n",
       "      <td>0.799935</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.655489</td>\n",
       "      <td>0.274452</td>\n",
       "      <td>0.161090</td>\n",
       "      <td>0.165572</td>\n",
       "      <td>0.277341</td>\n",
       "      <td>0.245546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154445</td>\n",
       "      <td>0.062250</td>\n",
       "      <td>0.140902</td>\n",
       "      <td>0.124953</td>\n",
       "      <td>0.136314</td>\n",
       "      <td>0.056547</td>\n",
       "      <td>0.345491</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>0.131318</td>\n",
       "      <td>0.131820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10128 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       delta_ch_1  delta_ch_2  delta_ch_3  delta_ch_4  delta_ch_5  delta_ch_6  \\\n",
       "5096     0.153181    0.350419    0.498484    0.157720    0.486005    0.566548   \n",
       "5272     0.476661    0.571317    0.603340    0.387782    0.553797    0.785409   \n",
       "5724     0.704278    0.578399    0.546968    0.714151    0.413070    0.690900   \n",
       "4399     0.405527    0.545927    0.564149    0.436535    0.487349    0.182151   \n",
       "312      0.639820    0.644632    0.633625    0.508083    0.550546    0.374616   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "5397     0.244472    0.782263    0.833547    0.774767    0.683594    0.530316   \n",
       "410      0.198776    0.245048    0.174620    0.303401    0.376952    0.222133   \n",
       "10881    0.210066    0.297961    0.367230    0.206470    0.464282    0.143529   \n",
       "5228     0.291022    0.328981    0.379860    0.393899    0.379593    0.487379   \n",
       "1063     0.346987    0.769568    0.799935    0.519139    0.655489    0.274452   \n",
       "\n",
       "       delta_ch_7  delta_ch_8  delta_ch_9  delta_ch_10  ...  gamma_ch_53  \\\n",
       "5096     0.584575    0.576647    0.152469     0.239082  ...     0.017715   \n",
       "5272     0.728427    0.727731    0.476403     0.483077  ...     0.042385   \n",
       "5724     0.708759    0.708311    0.567819     0.470531  ...     0.049085   \n",
       "4399     0.307276    0.482612    0.525807     0.439476  ...     0.000358   \n",
       "312      0.458939    0.468819    0.465676     0.469366  ...     0.044721   \n",
       "...           ...         ...         ...          ...  ...          ...   \n",
       "5397     0.624453    0.608354    0.410154     0.589162  ...     0.016059   \n",
       "410      0.338558    0.336561    0.334959     0.269705  ...     0.176179   \n",
       "10881    0.133425    0.134979    0.401385     0.301186  ...     0.096175   \n",
       "5228     0.401575    0.394238    0.313900     0.281180  ...     0.048904   \n",
       "1063     0.161090    0.165572    0.277341     0.245546  ...     0.154445   \n",
       "\n",
       "       gamma_ch_54  gamma_ch_55  gamma_ch_56  gamma_ch_57  gamma_ch_58  \\\n",
       "5096      0.032809     0.050606     0.046754     0.053185     0.043450   \n",
       "5272      0.046910     0.135830     0.154097     0.166189     0.066408   \n",
       "5724      0.072504     0.061273     0.083405     0.088006     0.055335   \n",
       "4399      0.000442     0.000912     0.000892     0.001008     0.000432   \n",
       "312       0.067957     0.052626     0.058225     0.069410     0.047011   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "5397      0.015164     0.015076     0.018705     0.022080     0.022978   \n",
       "410       0.118855     0.179979     0.080788     0.178276     0.179587   \n",
       "10881     0.075173     0.109514     0.096575     0.085295     0.135039   \n",
       "5228      0.050790     0.038233     0.066045     0.067044     0.153495   \n",
       "1063      0.062250     0.140902     0.124953     0.136314     0.056547   \n",
       "\n",
       "       gamma_ch_59  gamma_ch_60  gamma_ch_61  gamma_ch_62  \n",
       "5096      0.025892     0.047060     0.069642     0.045041  \n",
       "5272      0.092475     0.071719     0.229695     0.115491  \n",
       "5724      0.048416     0.064150     0.128891     0.082047  \n",
       "4399      0.000373     0.000441     0.000918     0.003061  \n",
       "312       0.040690     0.057681     0.083602     0.132935  \n",
       "...            ...          ...          ...          ...  \n",
       "5397      0.012342     0.015182     0.015216     0.014888  \n",
       "410       0.159779     0.158871     0.086228     0.112000  \n",
       "10881     0.119026     0.083509     0.169641     0.049063  \n",
       "5228      0.085527     0.093413     0.129107     0.113034  \n",
       "1063      0.345491     0.061749     0.131318     0.131820  \n",
       "\n",
       "[10128 rows x 310 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf333c7-6cb2-4dcb-ab0b-83ac84f0658c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc95a495-9fcf-41a0-baae-acaeb1d3bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the important packages\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.svm import SVC\n",
    " \n",
    "svm = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  \n",
    "    'gamma': [1, 0.1, 0.01,],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c46a5e2a-3088-4074-ab2b-2346b0dc2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "grs = GridSearchCV(svm, param_grid, refit=True, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "467f96a5-fc2a-4dfd-99a7-a6cbcc6bba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10128,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21f996ee-5e91-4a88-8eaa-583c781b000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting SVM:   0%|                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting SVM: 100%|███████████████████████████████| 1/1 [07:07<00:00, 427.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 217 ms, total: 14.2 s\n",
      "Wall time: 7min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.307 total time=  57.6s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.314 total time=  56.9s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.463 total time= 1.0min\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.494 total time=  47.5s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.404 total time=  52.4s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.484 total time=  56.6s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.487 total time=  51.5s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.463 total time=  46.4s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.463 total time=  46.8s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.312 total time=  56.7s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.506 total time=  44.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.489 total time=  43.8s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.489 total time=  44.1s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.500 total time=  52.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.475 total time=  50.4s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.307 total time=  57.4s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.461 total time=  47.1s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.461 total time=  47.7s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.483 total time=  44.1s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.487 total time=  43.4s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.487 total time=  43.8s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.475 total time=  51.9s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.501 total time=  50.9s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.460 total time=  45.6s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.376 total time=  54.5s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.314 total time=  57.5s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.516 total time=  48.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.496 total time=  44.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.491 total time=  57.5s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.575 total time=  41.9s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.495 total time=  42.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.461 total time=  46.2s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.379 total time=  55.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.460 total time=  46.8s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.440 total time=  59.8s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.402 total time=  52.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.496 total time=  57.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.552 total time=  41.6s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.475 total time=  39.1s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.468 total time=  46.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.379 total time=  54.6s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.463 total time=  46.9s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.441 total time=  59.4s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.407 total time=  52.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.484 total time=  57.6s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.584 total time=  42.4s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.490 total time=  39.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.306 total time=  57.1s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.468 total time=  47.6s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.465 total time= 1.0min\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.519 total time=  48.3s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.407 total time=  52.6s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.471 total time=  57.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.563 total time=  41.7s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.495 total time=  40.4s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.307 total time=  57.6s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.316 total time=  56.5s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.454 total time= 1.0min\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.524 total time=  47.9s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.397 total time=  52.4s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.495 total time=  52.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.495 total time=  52.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.500 total time=  32.3s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.306 total time=  57.2s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.451 total time=  47.1s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.451 total time=  47.2s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.487 total time=  44.6s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.506 total time=  43.3s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.506 total time=  43.8s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.487 total time=  52.7s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.495 total time=  44.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.475 total time=  31.9s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.451 total time=  46.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.379 total time=  55.2s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.468 total time=  47.6s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.489 total time=  44.5s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.515 total time=  47.6s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.483 total time=  43.5s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.501 total time=  51.3s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.500 total time=  43.6s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.487 total time=  32.5s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.380 total time=  53.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.460 total time=  47.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.316 total time=  57.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.496 total time=  44.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.483 total time=  42.7s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.496 total time=  43.2s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.583 total time=  42.4s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.500 total time=  51.2s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.501 total time=  31.4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#grs.fit(X_train, y_train)\n",
    "X_train_subset = X_train\n",
    "y_train_subset = y_train  \n",
    "\n",
    "# Fit the model with tqdm\n",
    "with tqdm(total=1, desc=\"Fitting SVM\") as pbar:\n",
    "    grs.fit(X_train_subset, y_train_subset)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce4ccb02-b36b-4cab-ba06-f5ab20a42194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CPU times: user 3.78 s, sys: 8.99 ms, total: 3.79 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Best Hyper Parameters:\",grs.best_params_)\n",
    "model_best = grs.best_estimator_\n",
    "y_pred = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17a84ed4-fb43-473b-b242-32e9ac84f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5983412322274881\n",
      "Precision: 0.6097277338656834\n",
      "Recall: 0.5983412322274881\n",
      "F1-score: 0.5957609468993151\n",
      "CPU times: user 2.66 ms, sys: 1.07 ms, total: 3.73 ms\n",
      "Wall time: 2.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"F1-score:\",metrics.f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "458ee869-29c9-44bb-937c-e2bb3e6e7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b89c3-1df7-496c-888a-6265d1add8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000 - 44.6%, 2 minutes\n",
    "# 10000 - 49.78%, 12 minutes\n",
    "# 2 Sessions: 55%, 29 minutes\n",
    "\n",
    "# 7000 - 46.96\n",
    "# 8000 - 48.57, Time taken: 20 minutes\n",
    "# 15000 - 52.23%, Time: 8 Hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
