{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b91aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d,MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(r\"C:\\Users\\sonam\\University of Canberra\\4th Semester\\Capstone\\Models\\Session_1_labels.csv\")\n",
    "master_csv.head()\n",
    "master_csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 360/360 [03:30<00:00,  1.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd() \n",
    "folder_path = os.path.join(cwd,\"session_1_all_200\")\n",
    "\n",
    "eeg_data=[]\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "     # Drop the first row (column headers)\n",
    "    file = file.iloc[1:]\n",
    "    \n",
    "    # Drop rows below row 6002\n",
    "    file = file.iloc[:6002]\n",
    "    \n",
    "    file = file.astype('float32')\n",
    "    eeg_values = file.drop(columns=['time']).values  # Assuming 'time' column is not needed\n",
    "    \n",
    "#     # Calculate mean and standard deviation for Z-score normalization\n",
    "#     mean = np.mean(eeg_values, axis=0)\n",
    "#     std_dev = np.std(eeg_values, axis=0)\n",
    "    \n",
    "#     # Apply Z-score normalization\n",
    "#     eeg_values_normalized = (eeg_values - mean) / std_dev\n",
    "    \n",
    "    # Transpose the EEG data\n",
    "    eeg_values= eeg_values.T\n",
    "    \n",
    "    eeg_data.append(eeg_values)\n",
    "# converting the list to numpy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "eeg_numpy.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de582e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fca2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8298626e+07,  1.3113022e+07,  1.2934208e+07, ...,\n",
       "         -7.7784060e+06, -1.3977289e+07, -1.7225742e+07],\n",
       "        [ 1.9699336e+07,  1.3023615e+07,  2.1100044e+07, ...,\n",
       "         -1.1712313e+07, -1.8119812e+07, -1.1950731e+07],\n",
       "        [ 1.6123056e+07,  1.2725592e+07,  1.7762184e+07, ...,\n",
       "         -3.1501054e+07, -3.5375360e+07, -3.0547380e+07],\n",
       "        ...,\n",
       "        [ 2.0742416e+07,  2.4825334e+07,  3.6150216e+07, ...,\n",
       "         -2.5898218e+07, -1.7911196e+07, -1.4126301e+07],\n",
       "        [ 2.2798776e+07,  2.6345252e+07,  3.4958124e+07, ...,\n",
       "         -1.4543533e+07, -4.6491625e+06, -9.2387200e+05],\n",
       "        [ 3.3259392e+07,  3.9786104e+07,  5.0812956e+07, ...,\n",
       "         -2.3096800e+07, -1.2308359e+07, -1.0937452e+07]],\n",
       "\n",
       "       [[-3.8146972e+06, -2.1159650e+06, -1.7225742e+07, ...,\n",
       "         -2.6166440e+07, -3.0547380e+07, -2.3365020e+07],\n",
       "        [ 1.8477440e+06, -5.0663947e+05, -1.2397766e+07, ...,\n",
       "         -1.8745660e+07, -2.5302172e+07, -2.2500754e+07],\n",
       "        [ 8.5234640e+06,  3.2782553e+05, -1.6987324e+06, ...,\n",
       "          1.2874603e+07,  1.7613172e+07,  2.4050474e+07],\n",
       "        ...,\n",
       "        [ 2.1487474e+07,  2.1517276e+07,  2.1785498e+07, ...,\n",
       "         -1.7523766e+07, -1.5228987e+07, -1.2189150e+07],\n",
       "        [ 2.5629998e+07,  2.3663044e+07,  2.2411346e+07, ...,\n",
       "         -2.5331974e+07, -2.3066998e+07, -2.7626752e+07],\n",
       "        [ 9.0897080e+06,  5.5134295e+06,  2.9206275e+06, ...,\n",
       "         -2.7894974e+07, -2.5898218e+07, -3.3169982e+07]],\n",
       "\n",
       "       [[-2.9504300e+06, -1.1265278e+07, -1.1563301e+07, ...,\n",
       "         -1.4781952e+07, -2.9206275e+06, -1.1771917e+07],\n",
       "        [-1.3589859e+07, -2.5421380e+07, -2.5689602e+07, ...,\n",
       "         -6.0200690e+06,  5.5730345e+06, -5.9604644e+05],\n",
       "        [-2.0474196e+07, -3.2633544e+07, -3.5703184e+07, ...,\n",
       "         -1.2755394e+07,  5.9604645e+04, -5.6624415e+06],\n",
       "        ...,\n",
       "        [ 2.7060508e+07,  2.5212764e+07,  1.7017126e+07, ...,\n",
       "         -1.0013580e+07, -8.0466270e+06, -8.7916850e+06],\n",
       "        [ 2.4825334e+07,  2.3514032e+07,  1.4334917e+07, ...,\n",
       "         -9.6261500e+06, -6.3776970e+06, -8.4638600e+06],\n",
       "        [ 3.6150216e+07,  3.3438206e+07,  2.4557114e+07, ...,\n",
       "          8.3446500e+05,  5.0663950e+06,  8.9406969e+05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.0769576e+07,  3.3378602e+07,  4.1782856e+07, ...,\n",
       "         -1.1861324e+07,  4.8607588e+07,  8.3446500e+05],\n",
       "        [ 3.7938356e+07,  2.8997660e+07,  3.6060812e+07, ...,\n",
       "         -3.2901764e+07,  4.1812660e+07, -1.9222498e+07],\n",
       "        [ 3.1679868e+07,  2.5868416e+07,  3.0636788e+07, ...,\n",
       "         -4.5418740e+07,  2.4408102e+07, -3.4511088e+07],\n",
       "        ...,\n",
       "        [-3.3676625e+06, -7.7486038e+05, -2.8312208e+06, ...,\n",
       "         -4.7326088e+07,  7.5697900e+06, -3.1948090e+07],\n",
       "        [-1.4394522e+07, -1.1771917e+07, -1.6480684e+07, ...,\n",
       "         -6.3300132e+07,  3.5762788e+05, -4.5299532e+07],\n",
       "        [-1.3351440e+07, -1.2010336e+07, -1.5556812e+07, ...,\n",
       "         -6.3002108e+07, -1.4901161e+06, -4.2647124e+07]],\n",
       "\n",
       "       [[-6.8485736e+07, -4.6640632e+07, -6.0111284e+07, ...,\n",
       "         -3.6865472e+07, -2.8163194e+07, -1.1742115e+07],\n",
       "        [-6.4343216e+07, -3.9488076e+07, -5.4687264e+07, ...,\n",
       "         -3.6031004e+07, -2.7775764e+07, -1.4305115e+07],\n",
       "        [-4.9918892e+07, -2.7954578e+07, -4.0590764e+07, ...,\n",
       "         -3.6299228e+07, -3.1471252e+07, -1.6957522e+07],\n",
       "        ...,\n",
       "        [-9.7155570e+06, -1.7285348e+06, -6.0498715e+06, ...,\n",
       "         -9.9539760e+06, -2.3990870e+07, -7.6591970e+06],\n",
       "        [-1.2278557e+07, -1.6987324e+06, -1.0609627e+07, ...,\n",
       "         -7.8380110e+06, -2.0027160e+07, -3.9041042e+06],\n",
       "        [-1.1444092e+07, -2.7120112e+06, -8.8512900e+06, ...,\n",
       "         -6.8843365e+06, -2.0414590e+07, -3.8444995e+06]],\n",
       "\n",
       "       [[-4.0501360e+07, -3.2722950e+07, -3.6686660e+07, ...,\n",
       "         -2.8908252e+07,  7.4505805e+06, -1.1861324e+07],\n",
       "        [-4.2974948e+07, -3.1441450e+07, -4.2945144e+07, ...,\n",
       "         -3.3915044e+07,  3.4570695e+06, -1.9788742e+07],\n",
       "        [-4.1127204e+07, -2.8371810e+07, -3.3497810e+07, ...,\n",
       "         -2.9385090e+07,  1.9669532e+06, -2.0623208e+07],\n",
       "        ...,\n",
       "        [-1.9967556e+07, -1.3768673e+07, -2.2828578e+07, ...,\n",
       "         -1.3798475e+07, -6.3776970e+06, -1.0013580e+07],\n",
       "        [-3.0219554e+07, -2.1874904e+07, -3.0130148e+07, ...,\n",
       "         -2.0891428e+07, -9.4175340e+06, -1.4156103e+07],\n",
       "        [-3.0130148e+07, -2.2143126e+07, -3.1173230e+07, ...,\n",
       "         -2.0027160e+07, -9.8943710e+06, -1.2338161e+07]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 2 0 0 1 0 1 2 1 1 1 2 3 2 2 3 3 0 3 0 3 1 2 3 0 2 0 0 1 0 1 2 1 1\n",
      " 1 2 3 2 2 3 3 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "print(label_emotion[:48])  # Display the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((270, 62, 6002), (270,)), ((90, 62, 6002), (90,)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d56606ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "# Reshape training data\n",
    "\n",
    "train_x = torch.from_numpy(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "081b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ea0f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([270, 62, 6002]), torch.Size([270]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f9ee06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data\n",
    "\n",
    "val_x = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06d69a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 62, 6002]), torch.Size([90]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6c45bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 1, 62, 6002])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming val_x is your input data\n",
    "val_x = val_x.unsqueeze(1)  # Add a dummy channel dimension\n",
    "\n",
    "# Shape of validation data after modification\n",
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92bedaaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Move the model to GPU if available\u001b[39;00m\n\u001b[0;32m     56\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 26\u001b[0m, in \u001b[0;36mNet.__init__\u001b[1;34m(self, in_channels, num_classes)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      7\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, \u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      8\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate the number of features after convolutional layers\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_num_features((\u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m6002\u001b[39m))  \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Fully connected layers\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     30\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features, \u001b[38;5;241m2048\u001b[39m),\n\u001b[0;32m     31\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1024\u001b[39m, num_classes)\n\u001b[0;32m     37\u001b[0m )\n",
      "Cell \u001b[1;32mIn[38], line 42\u001b[0m, in \u001b[0;36mNet._calculate_num_features\u001b[1;34m(self, input_dim)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_num_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Forward pass to get the shape after convolutional layers\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_dim)\n\u001b[1;32m---> 42\u001b[0m     conv_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_layers(input_tensor)\n\u001b[0;32m     43\u001b[0m     num_features \u001b[38;5;241m=\u001b[39m conv_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_features\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_dim(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:410\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 4D input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n",
      "\u001b[1;31mValueError\u001b[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):   \n",
    "    def __init__(self, in_channels=1, num_classes=4):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),                                      \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Calculate the number of features after convolutional layers\n",
    "        self.num_features = self._calculate_num_features((62, 6002))  \n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(self.num_features, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _calculate_num_features(self, input_dim):\n",
    "        # Forward pass to get the shape after convolutional layers\n",
    "        input_tensor = torch.zeros(1, *input_dim)\n",
    "        conv_output = self.cnn_layers(input_tensor)\n",
    "        num_features = conv_output.view(1, -1).size(1)\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Net()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e923a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (128x750x1). Calculated output size: (128x375x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# defining the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# defining the optimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m, in \u001b[0;36mNet.__init__\u001b[1;34m(self, in_channels, num_classes)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, \u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)                     \n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate the number of features after convolutional layers\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_num_features((\u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;241m10\u001b[39m))  \n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Fully connected layers\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     37\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features, \u001b[38;5;241m2048\u001b[39m),\n\u001b[0;32m     38\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1024\u001b[39m, num_classes)\n\u001b[0;32m     44\u001b[0m )\n",
      "Cell \u001b[1;32mIn[21], line 49\u001b[0m, in \u001b[0;36mNet._calculate_num_features\u001b[1;34m(self, input_dim)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_num_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Forward pass to get the shape after convolutional layers\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39minput_dim)\n\u001b[1;32m---> 49\u001b[0m     conv_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_layers(input_tensor)\n\u001b[0;32m     50\u001b[0m     num_features \u001b[38;5;241m=\u001b[39m conv_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_features\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    167\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, ceil_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[0;32m    168\u001b[0m                         return_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_indices)\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28minput\u001b[39m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (128x750x1). Calculated output size: (128x375x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# batch size of the model\n",
    "batch_size = 200\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e470b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 1.3872495889663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 2 \t training loss: \t 1.355642557144165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 3 \t training loss: \t 1.3294575810432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 4 \t training loss: \t 1.3134034276008606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 5 \t training loss: \t 1.2839776277542114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 6 \t training loss: \t 1.2878819704055786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 7 \t training loss: \t 1.2356016635894775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 8 \t training loss: \t 1.2219054698944092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 9 \t training loss: \t 1.2216623425483704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 10 \t training loss: \t 1.1848611235618591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 11 \t training loss: \t 1.1707348227500916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 12 \t training loss: \t 1.1687666177749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 13 \t training loss: \t 1.1410840153694153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 14 \t training loss: \t 1.1532792448997498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 15 \t training loss: \t 1.1515308022499084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 16 \t training loss: \t 1.1373720169067383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 17 \t training loss: \t 1.1639060378074646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 18 \t training loss: \t 1.1094833612442017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 19 \t training loss: \t 1.127306580543518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 20 \t training loss: \t 1.1192717552185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        # Convert batch_y to Long data type\n",
    "        batch_y = batch_y.long()  # Convert to Long data type\n",
    "        \n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27b031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb708a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0069c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
