{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d659353c-ded8-403f-afae-a07c1b05ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to detect a GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"Found a GPU with ID: \",gpu)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b91aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d,MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(\"MASTER_CSV_4.csv\")\n",
    "master_csv.head()\n",
    "master_csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12660/12660 [14:14<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12660, 1001, 62)\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd() \n",
    "folder_path = os.path.join(cwd,\"session_1\")\n",
    "\n",
    "# define custom transform function\n",
    "transform_tensor = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "eeg_data = []\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows below row 6002\n",
    "    #file = file.iloc[:6002]\n",
    "    \n",
    "    file = file.astype('float32')\n",
    "    #eeg_values = file.drop(columns=['time']).values  # Assuming 'time' column is not needed\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    mean, std = file.mean(), file.std()\n",
    "    \n",
    "    # Normalize EEG data\n",
    "    normalized_data = (file - mean) / std\n",
    "    \n",
    "    eeg_data.append(normalized_data)\n",
    "\n",
    "# Convert the list of normalized arrays to a NumPy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "print(eeg_numpy.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de582e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fca2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.1158739 ,  1.236367  ,  1.2142688 , ...,  1.4467032 ,\n",
       "          1.6951935 ,  1.7026098 ],\n",
       "        [ 1.6328441 ,  1.443384  ,  1.3650314 , ...,  1.7051029 ,\n",
       "          1.8625292 ,  1.8763801 ],\n",
       "        [ 1.2299114 ,  1.7298721 ,  1.1660248 , ...,  1.3870724 ,\n",
       "          1.5190508 ,  1.5187662 ],\n",
       "        ...,\n",
       "        [-0.9697455 , -1.283159  , -1.5356385 , ..., -1.0816393 ,\n",
       "         -0.64247245, -0.60677016],\n",
       "        [-1.1737459 , -1.7648908 , -1.7635913 , ..., -1.114436  ,\n",
       "         -0.46003878, -0.43174088],\n",
       "        [-0.9127267 , -1.3714602 , -1.0230461 , ..., -1.2674884 ,\n",
       "         -0.83622926, -0.8774991 ]],\n",
       "\n",
       "       [[ 2.528494  ,  2.4359193 ,  2.4094703 , ...,  0.3816055 ,\n",
       "          0.35974196,  0.43337438],\n",
       "        [ 3.455898  ,  3.6334217 ,  3.503844  , ..., -0.30513126,\n",
       "         -0.35826373, -0.38696492],\n",
       "        [ 4.0914726 ,  4.528642  ,  4.5213394 , ...,  0.5561996 ,\n",
       "          0.42966947,  0.41957662],\n",
       "        ...,\n",
       "        [-0.98761904, -0.9482108 , -0.93605655, ...,  0.18955201,\n",
       "         -0.49187523, -0.49985567],\n",
       "        [-1.7915267 , -1.9740028 , -2.344271  , ..., -1.8284647 ,\n",
       "         -2.3224776 , -2.286038  ],\n",
       "        [ 0.14351524,  0.21262449,  0.03259967, ...,  1.0217838 ,\n",
       "          0.56328094,  0.4672416 ]],\n",
       "\n",
       "       [[ 0.40963212, -0.784067  , -1.196917  , ...,  2.1423426 ,\n",
       "          1.044555  ,  1.0642828 ],\n",
       "        [ 0.2385767 , -0.910229  , -1.2897714 , ...,  2.197561  ,\n",
       "          1.08214   ,  1.1352397 ],\n",
       "        [ 0.33221132, -0.85173285, -1.0370858 , ...,  2.1503124 ,\n",
       "          1.0469468 ,  1.0772749 ],\n",
       "        ...,\n",
       "        [-0.4853688 , -0.5061309 , -0.43338013, ...,  1.2981317 ,\n",
       "          1.9414685 ,  1.9177644 ],\n",
       "        [-0.44807708, -0.5769588 , -0.50735915, ...,  1.208758  ,\n",
       "          1.888508  ,  1.8348148 ],\n",
       "        [-0.47645125, -0.5734806 , -0.5146657 , ...,  1.2098966 ,\n",
       "          1.8888496 ,  1.8468075 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.12158751,  0.11921417,  0.09324295, ...,  0.03426486,\n",
       "          0.04185327,  0.04197561],\n",
       "        [ 0.18965831,  0.13526496,  0.10509739, ...,  0.03287738,\n",
       "          0.0441261 ,  0.04450164],\n",
       "        [ 0.16778287,  0.13652384,  0.11644739, ...,  0.04233741,\n",
       "          0.04993444,  0.04968001],\n",
       "        ...,\n",
       "        [ 0.33457518,  0.25511083,  0.22906457, ...,  0.2669186 ,\n",
       "          0.25284758,  0.2524573 ],\n",
       "        [ 0.3513108 ,  0.2962764 ,  0.296534  , ...,  0.33212975,\n",
       "          0.31269875,  0.31276628],\n",
       "        [ 0.01709945, -0.04588863, -0.05380256, ..., -0.03283831,\n",
       "         -0.05120646, -0.05117184]],\n",
       "\n",
       "       [[ 0.8353321 ,  0.03885743, -0.21639974, ..., -0.47778827,\n",
       "         -2.665843  , -2.7247512 ],\n",
       "        [ 0.6629516 , -0.25830048, -0.6529931 , ...,  0.09378278,\n",
       "         -1.8113091 , -1.7548857 ],\n",
       "        [ 0.61670315, -0.39842376, -0.86031395, ...,  0.6137536 ,\n",
       "         -1.9498821 , -1.9228939 ],\n",
       "        ...,\n",
       "        [ 1.617351  ,  1.1308523 ,  0.35678145, ...,  0.60978436,\n",
       "         -2.3271089 , -2.1901796 ],\n",
       "        [ 1.3335538 ,  0.72256225, -0.03346957, ...,  0.87572366,\n",
       "         -2.2193298 , -2.3047307 ],\n",
       "        [ 1.6110444 ,  1.0221361 ,  0.13482618, ...,  0.5780304 ,\n",
       "         -2.4887774 , -2.4498289 ]],\n",
       "\n",
       "       [[ 1.2088604 ,  0.8006122 ,  0.7848311 , ...,  1.5871185 ,\n",
       "          1.4019492 ,  1.3522835 ],\n",
       "        [-0.8041777 , -1.0685779 , -1.0460889 , ..., -0.78652376,\n",
       "         -0.94562954, -0.90083736],\n",
       "        [ 1.4036163 ,  0.80888295,  0.4886874 , ...,  1.2483852 ,\n",
       "          1.3355652 ,  1.3512777 ],\n",
       "        ...,\n",
       "        [-0.65223444, -0.5210541 , -0.6418293 , ..., -1.2745507 ,\n",
       "         -1.417358  , -1.3715787 ],\n",
       "        [ 0.5053884 ,  0.7005361 ,  0.59915376, ..., -0.45531788,\n",
       "         -0.28279558, -0.33051613],\n",
       "        [ 0.09656872,  0.22662193, -0.00880263, ..., -0.6874129 ,\n",
       "         -0.8390128 , -0.7509646 ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 1001, 62)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape # 360, 400, 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3 3 0 3 0 1 0 2 1 3 1 3 1 1 0 2 2 2 2 3 1 2 0 3 3 3 3 1 2 1 1 0 3 3 0\n",
      " 0 1 2 2 3 0 2 1 3 3 1]\n"
     ]
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "print(label_emotion[:48])  # Display the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((9495, 1001, 62), (9495,)), ((3165, 1001, 62), (3165,)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3165, 1, 1001, 62]), torch.Size([3165]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting training images into torch format\n",
    "train_x = train_x.reshape(9495, 1, 1001, 62)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape\n",
    "\n",
    "# converting validation images into torch format\n",
    "val_x = val_x.reshape(3165, 1, 1001, 62)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y).long()\n",
    "\n",
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282aeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5bf4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetGray(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Adding pooling layer here to reduce spatial dimensions\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Final pooling to reduce size further if needed\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 125 * 7, 256),  # Adjusted size_after_conv to match output size from conv layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "#         print(f\"Output shape after convolutions: {out.shape}\")  # This will print the output shape\n",
    "        out = out.view(out.size(0), -1)  # Flatten the output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# nn.Linear(512 * 31 * 1, 256),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f3b0cf-6446-4693-935d-54dcd619cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a2a084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "ConvNetGray(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=112000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = ConvNetGray()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be388a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [15:43<00:00, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 1.7251576296488444\n",
      "CPU times: total: 1h 23min 41s\n",
      "Wall time: 15min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# batch size of the model\n",
    "batch_size = 128\n",
    "\n",
    "# Define parameters\n",
    "n_epochs = 10  # Define the maximum number of epochs\n",
    "early_stop_patience = 10  # Define patience for early stopping\n",
    "min_loss = float('inf')  # Initialize minimum loss\n",
    "best_epoch = 0  # Initialize the epoch with the best performance\n",
    "no_improvement_count = 0  # Initialize the count for early stopping\n",
    "\n",
    "train_losses = []  # List to store training losses\n",
    "\n",
    "# number of epochs to train the model\n",
    "#n_epochs = 15\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "    #permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        #if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(training_loss)\n",
    "\n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if training_loss < min_loss:\n",
    "        min_loss = training_loss\n",
    "        best_epoch = epoch\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= early_stop_patience:\n",
    "        print(f'Early stopping at epoch {epoch} with minimum loss {min_loss}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48cb44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [04:08<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 0.34405797101449276\n",
      "CPU times: total: 21min 48s\n",
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dbc6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:25<00:00,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.3215356182795699\n",
      "CPU times: total: 7min 32s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
