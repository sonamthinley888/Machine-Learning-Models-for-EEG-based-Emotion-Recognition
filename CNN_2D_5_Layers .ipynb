{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b91aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d,MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(r\"C:\\Users\\sonam\\University of Canberra\\4th Semester\\Capstone\\Models\\MASTER_CSV_4.csv\")\n",
    "master_csv.head()\n",
    "master_csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12660/12660 [05:18<00:00, 39.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12660, 1001, 62)\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd() \n",
    "folder_path = os.path.join(cwd,\"session_1\")\n",
    "\n",
    "\n",
    "eeg_data = []\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "    \n",
    "    eeg_values = file.astype('float32')\n",
    "    # Calculate mean and std\n",
    "    mean, std = eeg_values.mean(), eeg_values.std()\n",
    "    \n",
    "    # Normalize EEG data\n",
    "    normalized_data = (eeg_values - mean) / std\n",
    "    \n",
    "    eeg_data.append(normalized_data)\n",
    "\n",
    "# Convert the list of normalized arrays to a NumPy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "print(eeg_numpy.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de582e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b8fca2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.8213702 ,  0.80190176,  0.74304444, ...,  0.20115194,\n",
       "          0.15247741,  0.12589903],\n",
       "        [-0.56378865,  0.5369889 ,  0.18104266, ..., -0.02155637,\n",
       "         -0.23300526, -0.47552246],\n",
       "        [-1.1365596 ,  0.50063795, -0.01067706, ..., -0.19604553,\n",
       "         -0.5124569 , -0.80384374],\n",
       "        ...,\n",
       "        [ 0.89771086,  0.8076676 ,  0.97631395, ...,  0.7032685 ,\n",
       "          0.7107719 ,  0.7856219 ],\n",
       "        [ 0.74954593,  0.73610884,  0.90157044, ...,  0.5720468 ,\n",
       "          0.5625846 ,  0.55087525],\n",
       "        [ 0.63154274,  0.5298732 ,  0.4967377 , ...,  0.2804205 ,\n",
       "          0.24401589,  0.23140208]],\n",
       "\n",
       "       [[ 0.34617177,  0.33787128,  0.3630459 , ...,  0.3045646 ,\n",
       "          0.26065728,  0.2834916 ],\n",
       "        [ 0.11114397, -0.0477681 , -0.07044666, ..., -0.3479429 ,\n",
       "         -0.36172593, -0.02637697],\n",
       "        [ 0.02818565, -0.18522081, -0.22277236, ..., -0.86739564,\n",
       "         -0.7625559 , -0.46746096],\n",
       "        ...,\n",
       "        [-0.01469686, -0.33014822, -0.07334253, ...,  0.6731084 ,\n",
       "          0.58413213,  0.42241266],\n",
       "        [ 0.16998489, -0.05378587,  0.18845135, ...,  0.6607659 ,\n",
       "          0.6013147 ,  0.5362578 ],\n",
       "        [ 0.19010231,  0.20572285,  0.32437554, ...,  0.33816376,\n",
       "          0.29934818,  0.31294388]],\n",
       "\n",
       "       [[ 0.24012296,  0.09874285,  0.23247008, ...,  0.10129103,\n",
       "          0.17283553,  0.14614223],\n",
       "        [ 0.30980107,  0.0960196 , -0.12246133, ...,  1.0573617 ,\n",
       "          0.97482   ,  0.8348459 ],\n",
       "        [ 0.3769349 ,  0.37164584, -0.10011163, ...,  1.2344028 ,\n",
       "          0.9027065 ,  0.7182469 ],\n",
       "        ...,\n",
       "        [ 0.82844454,  0.8553131 ,  1.0047011 , ..., -0.01558835,\n",
       "         -0.00765106, -0.12941061],\n",
       "        [ 0.8999712 ,  0.76059854,  0.99194974, ..., -0.01467411,\n",
       "         -0.02396529,  0.08294599],\n",
       "        [ 0.25791693,  0.05855428,  0.28255445, ..., -0.03960538,\n",
       "          0.0908001 ,  0.09992238]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.03600974,  0.05347826,  0.06609374, ...,  0.00568038,\n",
       "          0.01075257,  0.01447547],\n",
       "        [ 0.34645748,  0.4085401 ,  0.43830362, ..., -0.25944445,\n",
       "         -0.26564184, -0.16591384],\n",
       "        [ 0.44765952,  0.4914392 ,  0.4495293 , ..., -0.29669684,\n",
       "         -0.382106  , -0.24866556],\n",
       "        ...,\n",
       "        [-0.36269537, -1.2767055 , -1.7861397 , ..., -0.063063  ,\n",
       "         -0.30406806, -0.33838415],\n",
       "        [-0.28206483, -0.9661723 , -1.3624535 , ..., -0.05088997,\n",
       "         -0.24855196, -0.27998537],\n",
       "        [ 0.16186202,  0.05317697, -0.09340928, ..., -0.02994971,\n",
       "         -0.12233782, -0.1287499 ]],\n",
       "\n",
       "       [[-0.07645704, -0.0615477 , -0.06503496, ..., -0.0408263 ,\n",
       "         -0.06262983, -0.0571624 ],\n",
       "        [-0.14570987, -0.15830965, -0.2678205 , ..., -0.80546737,\n",
       "         -1.3661098 , -1.23233   ],\n",
       "        [-0.19674437, -0.21046056, -0.37024602, ..., -1.3173819 ,\n",
       "         -1.8503325 , -1.6510086 ],\n",
       "        ...,\n",
       "        [-0.13701   , -0.20007716,  0.0092731 , ...,  0.14517905,\n",
       "          0.10038543,  0.09115023],\n",
       "        [ 0.6632821 ,  0.5478342 ,  0.6480667 , ...,  0.13095044,\n",
       "          0.00366435, -0.0096133 ],\n",
       "        [ 0.2365843 ,  0.22954829,  0.22445543, ...,  0.03545066,\n",
       "          0.05613725,  0.05058174]],\n",
       "\n",
       "       [[ 0.36608976,  0.33425173,  0.33804265, ..., -0.08655504,\n",
       "         -0.08265048, -0.08521874],\n",
       "        [-0.5843171 , -0.3555457 ,  0.03324312, ..., -0.70135534,\n",
       "         -0.38096455, -0.40857527],\n",
       "        [-1.0620105 , -0.72667676, -0.19420652, ..., -0.80328   ,\n",
       "         -0.33320615, -0.38006958],\n",
       "        ...,\n",
       "        [-0.9008921 , -0.7405779 , -0.6830613 , ..., -0.18279076,\n",
       "         -0.51179355, -0.4968324 ],\n",
       "        [-1.1278591 , -1.0060133 , -0.9315259 , ..., -0.21990575,\n",
       "         -0.5020784 , -0.48118854],\n",
       "        [ 0.02302801,  0.03085281,  0.00786761, ..., -0.1126822 ,\n",
       "         -0.13313952, -0.1319653 ]]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 400, 62)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 2 0 0 1 0 1 2 1 1 1 2 3 2 2 3 3 0 3 0 3 1 2 3 0 2 0 0 1 0 1 2 1 1\n",
      " 1 2 3 2 2 3 3 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "print(label_emotion[:48])  # Display the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((270, 400, 62), (270,)), ((90, 400, 62), (90,)))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 1, 400, 62]), torch.Size([90]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting training images into torch format\n",
    "train_x = train_x.reshape(270, 1, 400, 62)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape\n",
    "\n",
    "# converting validation images into torch format\n",
    "val_x = val_x.reshape(90, 1, 400, 62)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y).long()\n",
    "\n",
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282aeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f5bf4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetGray(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 12 * 1, 256),  # Adjusted to match the output from convolutional layers\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2(x)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a2a084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNetGray(\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU()\n",
      "    (18): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (20): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (21): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6144, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = ConvNetGray()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "#if torch.cuda.is_available():\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be388a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:19<00:00, 26.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 1.420012354850769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:03<00:00, 21.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 2 \t training loss: \t 1.0555397470792134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:02<00:00, 20.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 3 \t training loss: \t 0.8697951336701711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 4 \t training loss: \t 0.6792604972918829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 5 \t training loss: \t 0.4919968644777934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 6 \t training loss: \t 0.31519245853026706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 7 \t training loss: \t 0.17488898088534674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:02<00:00, 20.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 8 \t training loss: \t 0.08593431704988082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 9 \t training loss: \t 0.04074608216372629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:02<00:00, 20.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 10 \t training loss: \t 0.024623617219428223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 11 \t training loss: \t 0.0165950118098408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:01<00:00, 20.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 12 \t training loss: \t 0.02158821391640231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:02<00:00, 20.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 13 \t training loss: \t 0.022095393564086407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:02<00:00, 20.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 14 \t training loss: \t 0.020061676438975457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:03<00:00, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 15 \t training loss: \t 0.005418449213417868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch size of the model\n",
    "batch_size = 128\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "#     permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        #if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "48cb44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2dbc6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.34444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
