{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b91aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d,MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cz_eeg_data_1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cz_eeg_data_2.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cz_eeg_data_3.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cz_eeg_data_4.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cz_eeg_data_5.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  session subject  emotion\n",
       "0  cz_eeg_data_1.csv        1      cz        1\n",
       "1  cz_eeg_data_2.csv        1      cz        2\n",
       "2  cz_eeg_data_3.csv        1      cz        3\n",
       "3  cz_eeg_data_4.csv        1      cz        0\n",
       "4  cz_eeg_data_5.csv        1      cz        2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(r\"C:\\Users\\sonam\\University of Canberra\\4th Semester\\Capstone\\Models\\Sub CSV.csv\")\n",
    "master_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd() \n",
    "folder_path = os.path.join(cwd,\"cz_200\")\n",
    "\n",
    "eeg_data=[]\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop the first row (column headers)\n",
    "    file = file.iloc[1:]\n",
    "    \n",
    "    # Drop rows below row 9600\n",
    "    file = file.iloc[:6002]\n",
    "    \n",
    "    file = file.astype('float32')\n",
    "    eeg_values = file.drop(columns=['time']).values  # Assuming 'time' column is not needed\n",
    "    \n",
    "#      # Min-max normalization\n",
    "#     min_val = np.min(eeg_values)\n",
    "#     max_val = np.max(eeg_values)\n",
    "#     eeg_values_normalized = (eeg_values - min_val) / (max_val - min_val)\n",
    "    \n",
    "        \n",
    "#     # Calculate mean and standard deviation for Z-score normalization\n",
    "#     mean = np.mean(eeg_values, axis=0)\n",
    "#     std_dev = np.std(eeg_values, axis=0)\n",
    "    \n",
    "#     # Apply Z-score normalization\n",
    "#     eeg_values_normalized = (eeg_values - mean) / std_dev\n",
    "    \n",
    "    \n",
    "    # Transpose the EEG data\n",
    "    eeg_values = eeg_values.T\n",
    "    \n",
    "    eeg_data.append(eeg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d8dd9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 62, 6002)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "eeg_numpy.shape\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de582e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 62, 6002)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 3, 2, 2, 3, 3, 0, 3,\n",
       "       0, 3], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "label_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((18, 62, 6002), (18,)), ((6, 62, 6002), (6,)))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d56606ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "\n",
    "train_x = torch.from_numpy(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "081b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ea0f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 62, 6002]), torch.Size([18]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f9ee06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_x = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06d69a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 62, 6002]), torch.Size([6]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf1c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3e36c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
    "            nn.Conv2d(256, 64, kernel_size=4, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Calculate the number of features after convolutional layers\n",
    "        self.num_features = self._calculate_num_features((62, 6002))\n",
    "\n",
    "\n",
    "        \n",
    "        # Adjusted the input size of the first linear layer\n",
    "        self.lin1 = nn.Linear(self.num_features, 1024)  # Adjusted the input size\n",
    "        self.lin2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        \n",
    "    def _calculate_num_features(self, input_dim):\n",
    "        input_tensor = torch.zeros(1, *input_dim)\n",
    "        conv_output = self.conv1(input_tensor)\n",
    "        conv_output = self.conv2(conv_output)\n",
    "        conv_output = self.conv3(conv_output)\n",
    "        conv_output = self.conv4(conv_output)\n",
    "        num_features = conv_output.view(1, -1).size(1)\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2e923a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 97550073856 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# defining the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# defining the optimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[84], line 32\u001b[0m, in \u001b[0;36mCNN.__init__\u001b[1;34m(self, in_channels, num_classes)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_num_features((\u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m6002\u001b[39m))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Adjusted the input size of the first linear layer\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features, \u001b[38;5;241m1024\u001b[39m)  \u001b[38;5;66;03m# Adjusted the input size\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1024\u001b[39m, num_classes)\n",
      "File \u001b[1;32mC:\\Anaconda\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 97550073856 bytes."
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = CNN()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "#if torch.cuda.is_available():\n",
    "device='cpu'\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# batch size of the model\n",
    "batch_size = 200\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        # Convert batch_y to Long data type\n",
    "        batch_y = batch_y.long()  # Convert to Long data type\n",
    "        \n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb708a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0069c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
