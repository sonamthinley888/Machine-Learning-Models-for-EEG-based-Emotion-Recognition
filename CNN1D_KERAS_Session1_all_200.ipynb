{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b9445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import cheby1, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9705c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eeg-filters in c:\\anaconda\\anaconda3\\lib\\site-packages (0.0.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\anaconda\\anaconda3\\lib\\site-packages (from eeg-filters) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.4 in c:\\anaconda\\anaconda3\\lib\\site-packages (from eeg-filters) (1.11.1)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from eeg-filters) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (10.2.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=3.1->eeg-filters) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1->eeg-filters) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Anaconda\\Anaconda3\\Lib\\site-packages\\vtk-9.0.3.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Anaconda\\Anaconda3\\Lib\\site-packages\\vtk-9.0.3.egg-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "pip install eeg-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f031a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() \n",
    "folder_path = os.path.join(cwd,\"session_1_all_200\")\n",
    "file_path = os.path.join(folder_path,\"cz_eeg_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8652efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee197e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a21f535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>FP1</th>\n",
       "      <th>FPZ</th>\n",
       "      <th>FP2</th>\n",
       "      <th>AF3</th>\n",
       "      <th>AF4</th>\n",
       "      <th>F7</th>\n",
       "      <th>F5</th>\n",
       "      <th>F3</th>\n",
       "      <th>F1</th>\n",
       "      <th>...</th>\n",
       "      <th>PO3</th>\n",
       "      <th>POZ</th>\n",
       "      <th>PO4</th>\n",
       "      <th>PO6</th>\n",
       "      <th>PO8</th>\n",
       "      <th>CB1</th>\n",
       "      <th>O1</th>\n",
       "      <th>OZ</th>\n",
       "      <th>O2</th>\n",
       "      <th>CB2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.712011e+06</td>\n",
       "      <td>9.179115e+06</td>\n",
       "      <td>8.821487e+06</td>\n",
       "      <td>1.558661e+07</td>\n",
       "      <td>1.746416e+07</td>\n",
       "      <td>1.642108e+07</td>\n",
       "      <td>2.020597e+07</td>\n",
       "      <td>1.972914e+07</td>\n",
       "      <td>1.814961e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.247095e+07</td>\n",
       "      <td>1.612306e+07</td>\n",
       "      <td>2.348423e+07</td>\n",
       "      <td>1.990795e+07</td>\n",
       "      <td>4.988909e+07</td>\n",
       "      <td>2.276897e+07</td>\n",
       "      <td>2.229214e+07</td>\n",
       "      <td>2.437830e+07</td>\n",
       "      <td>2.774596e+07</td>\n",
       "      <td>3.850460e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>1.829863e+07</td>\n",
       "      <td>1.969934e+07</td>\n",
       "      <td>1.612306e+07</td>\n",
       "      <td>1.928210e+07</td>\n",
       "      <td>2.452731e+07</td>\n",
       "      <td>1.668930e+07</td>\n",
       "      <td>2.014637e+07</td>\n",
       "      <td>1.928210e+07</td>\n",
       "      <td>1.969934e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943111e+07</td>\n",
       "      <td>1.215935e+07</td>\n",
       "      <td>2.256036e+07</td>\n",
       "      <td>2.029538e+07</td>\n",
       "      <td>5.140900e+07</td>\n",
       "      <td>1.913309e+07</td>\n",
       "      <td>1.952052e+07</td>\n",
       "      <td>2.074242e+07</td>\n",
       "      <td>2.279878e+07</td>\n",
       "      <td>3.325939e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.311302e+07</td>\n",
       "      <td>1.302361e+07</td>\n",
       "      <td>1.272559e+07</td>\n",
       "      <td>1.671910e+07</td>\n",
       "      <td>2.086163e+07</td>\n",
       "      <td>3.445148e+07</td>\n",
       "      <td>1.919270e+07</td>\n",
       "      <td>1.937151e+07</td>\n",
       "      <td>1.838803e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.497435e+07</td>\n",
       "      <td>1.463294e+07</td>\n",
       "      <td>2.169609e+07</td>\n",
       "      <td>2.014637e+07</td>\n",
       "      <td>4.857779e+07</td>\n",
       "      <td>2.363324e+07</td>\n",
       "      <td>2.509356e+07</td>\n",
       "      <td>2.482533e+07</td>\n",
       "      <td>2.634525e+07</td>\n",
       "      <td>3.978610e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>1.293421e+07</td>\n",
       "      <td>2.110004e+07</td>\n",
       "      <td>1.776218e+07</td>\n",
       "      <td>2.348423e+07</td>\n",
       "      <td>2.703071e+07</td>\n",
       "      <td>3.159046e+07</td>\n",
       "      <td>2.488494e+07</td>\n",
       "      <td>2.452731e+07</td>\n",
       "      <td>2.488494e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.495812e+07</td>\n",
       "      <td>2.247095e+07</td>\n",
       "      <td>2.530217e+07</td>\n",
       "      <td>2.482533e+07</td>\n",
       "      <td>5.775690e+07</td>\n",
       "      <td>3.418327e+07</td>\n",
       "      <td>3.463030e+07</td>\n",
       "      <td>3.615022e+07</td>\n",
       "      <td>3.495812e+07</td>\n",
       "      <td>5.081296e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020</td>\n",
       "      <td>4.827976e+06</td>\n",
       "      <td>8.285046e+06</td>\n",
       "      <td>6.794930e+06</td>\n",
       "      <td>1.555681e+07</td>\n",
       "      <td>1.692772e+07</td>\n",
       "      <td>2.914667e+07</td>\n",
       "      <td>1.811981e+07</td>\n",
       "      <td>1.838803e+07</td>\n",
       "      <td>1.719594e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.154444e+07</td>\n",
       "      <td>2.279878e+07</td>\n",
       "      <td>2.387166e+07</td>\n",
       "      <td>2.482533e+07</td>\n",
       "      <td>5.492568e+07</td>\n",
       "      <td>4.068017e+07</td>\n",
       "      <td>4.103780e+07</td>\n",
       "      <td>3.999472e+07</td>\n",
       "      <td>3.710389e+07</td>\n",
       "      <td>5.134940e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time           FP1           FPZ           FP2           AF3  \\\n",
       "0  0.000  2.712011e+06  9.179115e+06  8.821487e+06  1.558661e+07   \n",
       "1  0.005  1.829863e+07  1.969934e+07  1.612306e+07  1.928210e+07   \n",
       "2  0.010  1.311302e+07  1.302361e+07  1.272559e+07  1.671910e+07   \n",
       "3  0.015  1.293421e+07  2.110004e+07  1.776218e+07  2.348423e+07   \n",
       "4  0.020  4.827976e+06  8.285046e+06  6.794930e+06  1.555681e+07   \n",
       "\n",
       "            AF4            F7            F5            F3            F1  ...  \\\n",
       "0  1.746416e+07  1.642108e+07  2.020597e+07  1.972914e+07  1.814961e+07  ...   \n",
       "1  2.452731e+07  1.668930e+07  2.014637e+07  1.928210e+07  1.969934e+07  ...   \n",
       "2  2.086163e+07  3.445148e+07  1.919270e+07  1.937151e+07  1.838803e+07  ...   \n",
       "3  2.703071e+07  3.159046e+07  2.488494e+07  2.452731e+07  2.488494e+07  ...   \n",
       "4  1.692772e+07  2.914667e+07  1.811981e+07  1.838803e+07  1.719594e+07  ...   \n",
       "\n",
       "            PO3           POZ           PO4           PO6           PO8  \\\n",
       "0  2.247095e+07  1.612306e+07  2.348423e+07  1.990795e+07  4.988909e+07   \n",
       "1  1.943111e+07  1.215935e+07  2.256036e+07  2.029538e+07  5.140900e+07   \n",
       "2  2.497435e+07  1.463294e+07  2.169609e+07  2.014637e+07  4.857779e+07   \n",
       "3  3.495812e+07  2.247095e+07  2.530217e+07  2.482533e+07  5.775690e+07   \n",
       "4  4.154444e+07  2.279878e+07  2.387166e+07  2.482533e+07  5.492568e+07   \n",
       "\n",
       "            CB1            O1            OZ            O2           CB2  \n",
       "0  2.276897e+07  2.229214e+07  2.437830e+07  2.774596e+07  3.850460e+07  \n",
       "1  1.913309e+07  1.952052e+07  2.074242e+07  2.279878e+07  3.325939e+07  \n",
       "2  2.363324e+07  2.509356e+07  2.482533e+07  2.634525e+07  3.978610e+07  \n",
       "3  3.418327e+07  3.463030e+07  3.615022e+07  3.495812e+07  5.081296e+07  \n",
       "4  4.068017e+07  4.103780e+07  3.999472e+07  3.710389e+07  5.134940e+07  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9731eaa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Maxpooling1D' from 'keras.layers' (C:\\Anaconda\\Anaconda3\\Lib\\site-packages\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Input, Model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Flatten\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D, Conv2D, Maxpooling1D, Maxpooling2D\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madvanced_activation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LeakyReLU\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Maxpooling1D' from 'keras.layers' (C:\\Anaconda\\Anaconda3\\Lib\\site-packages\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# from tensorflow.keras import Sequential, Input, Model\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "# from keras.layers import Conv1D, Conv2D, Maxpooling1D, Maxpooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.advanced_activation import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7c5d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b61138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(r\"C:\\Users\\sonam\\University of Canberra\\4th Semester\\Capstone\\Models\\Session_1_labels.csv\")\n",
    "master_csv.head()\n",
    "master_csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [03:36<00:00,  1.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "eeg_data=[]\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "     # Drop the first row (column headers)\n",
    "    file = file.iloc[1:]\n",
    "    \n",
    "    # Drop rows below row 6002\n",
    "    file = file.iloc[:6002]\n",
    "    \n",
    "    file = file.astype('float32')\n",
    "    eeg_values = file.drop(columns=['time']).values  # Assuming 'time' column is not needed\n",
    "    \n",
    "#     # Calculate mean and standard deviation for Z-score normalization\n",
    "#     mean = np.mean(eeg_values, axis=0)\n",
    "#     std_dev = np.std(eeg_values, axis=0)\n",
    "    \n",
    "#     # Apply Z-score normalization\n",
    "#     eeg_values_normalized = (eeg_values - mean) / std_dev\n",
    "    \n",
    "    # Transpose the EEG data\n",
    "    eeg_values= eeg_values.T\n",
    "    \n",
    "    eeg_data.append(eeg_values)\n",
    "# converting the list to numpy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "eeg_numpy.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de582e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8fca2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8298626e+07,  1.3113022e+07,  1.2934208e+07, ...,\n",
       "         -7.7784060e+06, -1.3977289e+07, -1.7225742e+07],\n",
       "        [ 1.9699336e+07,  1.3023615e+07,  2.1100044e+07, ...,\n",
       "         -1.1712313e+07, -1.8119812e+07, -1.1950731e+07],\n",
       "        [ 1.6123056e+07,  1.2725592e+07,  1.7762184e+07, ...,\n",
       "         -3.1501054e+07, -3.5375360e+07, -3.0547380e+07],\n",
       "        ...,\n",
       "        [ 2.0742416e+07,  2.4825334e+07,  3.6150216e+07, ...,\n",
       "         -2.5898218e+07, -1.7911196e+07, -1.4126301e+07],\n",
       "        [ 2.2798776e+07,  2.6345252e+07,  3.4958124e+07, ...,\n",
       "         -1.4543533e+07, -4.6491625e+06, -9.2387200e+05],\n",
       "        [ 3.3259392e+07,  3.9786104e+07,  5.0812956e+07, ...,\n",
       "         -2.3096800e+07, -1.2308359e+07, -1.0937452e+07]],\n",
       "\n",
       "       [[-3.8146972e+06, -2.1159650e+06, -1.7225742e+07, ...,\n",
       "         -2.6166440e+07, -3.0547380e+07, -2.3365020e+07],\n",
       "        [ 1.8477440e+06, -5.0663947e+05, -1.2397766e+07, ...,\n",
       "         -1.8745660e+07, -2.5302172e+07, -2.2500754e+07],\n",
       "        [ 8.5234640e+06,  3.2782553e+05, -1.6987324e+06, ...,\n",
       "          1.2874603e+07,  1.7613172e+07,  2.4050474e+07],\n",
       "        ...,\n",
       "        [ 2.1487474e+07,  2.1517276e+07,  2.1785498e+07, ...,\n",
       "         -1.7523766e+07, -1.5228987e+07, -1.2189150e+07],\n",
       "        [ 2.5629998e+07,  2.3663044e+07,  2.2411346e+07, ...,\n",
       "         -2.5331974e+07, -2.3066998e+07, -2.7626752e+07],\n",
       "        [ 9.0897080e+06,  5.5134295e+06,  2.9206275e+06, ...,\n",
       "         -2.7894974e+07, -2.5898218e+07, -3.3169982e+07]],\n",
       "\n",
       "       [[-2.9504300e+06, -1.1265278e+07, -1.1563301e+07, ...,\n",
       "         -1.4781952e+07, -2.9206275e+06, -1.1771917e+07],\n",
       "        [-1.3589859e+07, -2.5421380e+07, -2.5689602e+07, ...,\n",
       "         -6.0200690e+06,  5.5730345e+06, -5.9604644e+05],\n",
       "        [-2.0474196e+07, -3.2633544e+07, -3.5703184e+07, ...,\n",
       "         -1.2755394e+07,  5.9604645e+04, -5.6624415e+06],\n",
       "        ...,\n",
       "        [ 2.7060508e+07,  2.5212764e+07,  1.7017126e+07, ...,\n",
       "         -1.0013580e+07, -8.0466270e+06, -8.7916850e+06],\n",
       "        [ 2.4825334e+07,  2.3514032e+07,  1.4334917e+07, ...,\n",
       "         -9.6261500e+06, -6.3776970e+06, -8.4638600e+06],\n",
       "        [ 3.6150216e+07,  3.3438206e+07,  2.4557114e+07, ...,\n",
       "          8.3446500e+05,  5.0663950e+06,  8.9406969e+05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.0769576e+07,  3.3378602e+07,  4.1782856e+07, ...,\n",
       "         -1.1861324e+07,  4.8607588e+07,  8.3446500e+05],\n",
       "        [ 3.7938356e+07,  2.8997660e+07,  3.6060812e+07, ...,\n",
       "         -3.2901764e+07,  4.1812660e+07, -1.9222498e+07],\n",
       "        [ 3.1679868e+07,  2.5868416e+07,  3.0636788e+07, ...,\n",
       "         -4.5418740e+07,  2.4408102e+07, -3.4511088e+07],\n",
       "        ...,\n",
       "        [-3.3676625e+06, -7.7486038e+05, -2.8312208e+06, ...,\n",
       "         -4.7326088e+07,  7.5697900e+06, -3.1948090e+07],\n",
       "        [-1.4394522e+07, -1.1771917e+07, -1.6480684e+07, ...,\n",
       "         -6.3300132e+07,  3.5762788e+05, -4.5299532e+07],\n",
       "        [-1.3351440e+07, -1.2010336e+07, -1.5556812e+07, ...,\n",
       "         -6.3002108e+07, -1.4901161e+06, -4.2647124e+07]],\n",
       "\n",
       "       [[-6.8485736e+07, -4.6640632e+07, -6.0111284e+07, ...,\n",
       "         -3.6865472e+07, -2.8163194e+07, -1.1742115e+07],\n",
       "        [-6.4343216e+07, -3.9488076e+07, -5.4687264e+07, ...,\n",
       "         -3.6031004e+07, -2.7775764e+07, -1.4305115e+07],\n",
       "        [-4.9918892e+07, -2.7954578e+07, -4.0590764e+07, ...,\n",
       "         -3.6299228e+07, -3.1471252e+07, -1.6957522e+07],\n",
       "        ...,\n",
       "        [-9.7155570e+06, -1.7285348e+06, -6.0498715e+06, ...,\n",
       "         -9.9539760e+06, -2.3990870e+07, -7.6591970e+06],\n",
       "        [-1.2278557e+07, -1.6987324e+06, -1.0609627e+07, ...,\n",
       "         -7.8380110e+06, -2.0027160e+07, -3.9041042e+06],\n",
       "        [-1.1444092e+07, -2.7120112e+06, -8.8512900e+06, ...,\n",
       "         -6.8843365e+06, -2.0414590e+07, -3.8444995e+06]],\n",
       "\n",
       "       [[-4.0501360e+07, -3.2722950e+07, -3.6686660e+07, ...,\n",
       "         -2.8908252e+07,  7.4505805e+06, -1.1861324e+07],\n",
       "        [-4.2974948e+07, -3.1441450e+07, -4.2945144e+07, ...,\n",
       "         -3.3915044e+07,  3.4570695e+06, -1.9788742e+07],\n",
       "        [-4.1127204e+07, -2.8371810e+07, -3.3497810e+07, ...,\n",
       "         -2.9385090e+07,  1.9669532e+06, -2.0623208e+07],\n",
       "        ...,\n",
       "        [-1.9967556e+07, -1.3768673e+07, -2.2828578e+07, ...,\n",
       "         -1.3798475e+07, -6.3776970e+06, -1.0013580e+07],\n",
       "        [-3.0219554e+07, -2.1874904e+07, -3.0130148e+07, ...,\n",
       "         -2.0891428e+07, -9.4175340e+06, -1.4156103e+07],\n",
       "        [-3.0130148e+07, -2.2143126e+07, -3.1173230e+07, ...,\n",
       "         -2.0027160e+07, -9.8943710e+06, -1.2338161e+07]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 2 0 0 1 0 1 2 1 1 1 2 3 2 2 3 3 0 3 0 3 1 2 3 0 2 0 0 1 0 1 2 1 1\n",
      " 1 2 3 2 2 3 3 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "print(label_emotion[:48])  # Display the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((270, 62, 6002), (270,)), ((90, 62, 6002), (90,)))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d56606ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "# Reshape training data\n",
    "\n",
    "train_x = torch.from_numpy(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "081b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ea0f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([270, 62, 6002]), torch.Size([270]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f9ee06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data\n",
    "\n",
    "val_x = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06d69a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 62, 6002]), torch.Size([90]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92bedaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):   \n",
    "    def __init__(self, in_channels=62, num_classes=4):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),  \n",
    "            nn.BatchNorm1d(512),                                      \n",
    "            nn.ReLU(inplace=True),                                    \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)                     \n",
    "        )\n",
    "        \n",
    "        # Calculate the number of features after convolutional layers\n",
    "        self.num_features = self._calculate_num_features((62, 6000))  # Assuming input size is (62, 2000)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(self.num_features, 2048),  # Increased neurons\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024),                # Increased neurons\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _calculate_num_features(self, input_dim):\n",
    "        # Forward pass to get the shape after convolutional layers\n",
    "        input_tensor = torch.zeros(1, *input_dim)\n",
    "        conv_output = self.cnn_layers(input_tensor)\n",
    "        num_features = conv_output.view(1, -1).size(1)\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2e923a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv1d(62, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=11776, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# batch size of the model\n",
    "batch_size = 200\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e470b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 1.3872495889663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 2 \t training loss: \t 1.355642557144165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 3 \t training loss: \t 1.3294575810432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 4 \t training loss: \t 1.3134034276008606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 5 \t training loss: \t 1.2839776277542114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 6 \t training loss: \t 1.2878819704055786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 7 \t training loss: \t 1.2356016635894775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 8 \t training loss: \t 1.2219054698944092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 9 \t training loss: \t 1.2216623425483704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 10 \t training loss: \t 1.1848611235618591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 11 \t training loss: \t 1.1707348227500916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 12 \t training loss: \t 1.1687666177749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 13 \t training loss: \t 1.1410840153694153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 14 \t training loss: \t 1.1532792448997498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 15 \t training loss: \t 1.1515308022499084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 16 \t training loss: \t 1.1373720169067383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 17 \t training loss: \t 1.1639060378074646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 18 \t training loss: \t 1.1094833612442017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 19 \t training loss: \t 1.127306580543518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 20 \t training loss: \t 1.1192717552185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        # Convert batch_y to Long data type\n",
    "        batch_y = batch_y.long()  # Convert to Long data type\n",
    "        \n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27b031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb708a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0069c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
