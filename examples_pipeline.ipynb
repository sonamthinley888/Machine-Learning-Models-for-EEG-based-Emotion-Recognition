{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using TorchEEG to Complete a Deep Learning Workflow\n",
    "\n",
    "In this tutorial, we demonstrate a complete deep learning workflow using TorchEEG. We will cover the following aspects:\n",
    "\n",
    "1. Utilizing Datasets and Transformers in TorchEEG\n",
    "2. Data Partitioning Strategies in TorchEEG\n",
    "3. Leveraging Models and Trainers in TorchEEG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the Dataset\n",
    "\n",
    "We use the DEAP dataset supported by TorchEEG. Each EEG sample is set to\n",
    "be 1 second long, encompassing 128 data points. The baseline signal is 3\n",
    "seconds long, which we divide into three sections and then average to\n",
    "obtain the trial’s baseline signal.\n",
    "\n",
    "During offline preprocessing, we divide each electrode’s EEG signal into\n",
    "4 sub-bands, calculate the differential entropy for each sub-band as a\n",
    "feature, perform debaselining, and map onto a grid. Finally, the\n",
    "preprocessed EEG signals are saved locally. For online processing, we\n",
    "convert all EEG signals into Tensors, making them suitable for neural\n",
    "network input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torcheeg.datasets.constants.emotion_recognition.seediv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorcheeg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SEEDIVFeatureDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorcheeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorcheeg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01memotion_recognition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseediv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[0;32m      5\u001b[0m     SEED_CHANNEL_LOCATION_DICT\n\u001b[0;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SEEDIVFeatureDataset(root_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./eeg_feature_smooth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mde_movingAve\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m                                offline_transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToGrid         (SEED_CHANNEL_LOCATION_DICT),\n\u001b[0;32m     10\u001b[0m                                online_transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     11\u001b[0m                                label_transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mSelect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torcheeg.datasets.constants.emotion_recognition.seediv'"
     ]
    }
   ],
   "source": [
    "from torcheeg.datasets import SEEDIVFeatureDataset\n",
    "from torcheeg import transforms\n",
    "\n",
    "from torcheeg.datasets.constants.emotion_recognition.seediv import \\\n",
    "    SEED_CHANNEL_LOCATION_DICT\n",
    "\n",
    "dataset = SEEDIVFeatureDataset(root_path='./eeg_feature_smooth',\n",
    "                               features=['de_movingAve'],\n",
    "                               offline_transform=transforms.ToGrid         (SEED_CHANNEL_LOCATION_DICT),\n",
    "                               online_transform=transforms.ToTensor(),\n",
    "                               label_transform=transforms.Select('emotion'))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Dataset into Training and Test Sets\n",
    "\n",
    "In this case, we use per-subject 5-fold cross-validation to split the\n",
    "dataset. During this process, we separate each subject’s EEG samples\n",
    "into training and test sets. We use 4 folds for training and 1 fold for\n",
    "testing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "\n",
    "k_fold = KFoldGroupbyTrial(n_splits=10,\n",
    "                           split_path='./examples_pipeline/split',\n",
    "                           shuffle=True,\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Model and Initiate Training\n",
    "\n",
    "We loop through each cross-validation set, and for each one, we\n",
    "initialize the CCNN model and define its hyperparameters. For instance,\n",
    "each EEG sample contains 4-channel features from 4 sub-bands, and the\n",
    "grid size is 9x9.\n",
    "\n",
    "We then train the model for 50 epochs using the ``ClassifierTrainer``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorcheeg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierTrainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_dataset, val_dataset) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(k_fold\u001b[38;5;241m.\u001b[39msplit(dataset)):\n\u001b[0;32m      9\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torcheeg.models import CCNN\n",
    "\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = CCNN(num_classes=2, in_channels=4, grid_size=(9, 9))\n",
    "\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=2,\n",
    "                                lr=1e-4,\n",
    "                                weight_decay=1e-4,\n",
    "                                accelerator=\"gpu\")\n",
    "    trainer.fit(train_loader,\n",
    "                val_loader,\n",
    "                max_epochs=50,\n",
    "                default_root_dir=f'./examples_pipeline/model/{i}',\n",
    "                callbacks=[pl.callbacks.ModelCheckpoint(save_last=True)],\n",
    "                enable_progress_bar=True,\n",
    "                enable_model_summary=True,\n",
    "                limit_val_batches=0.0)\n",
    "    score = trainer.test(val_loader,\n",
    "                         enable_progress_bar=True,\n",
    "                         enable_model_summary=True)[0]\n",
    "    print(f'Fold {i} test accuracy: {score[\"test_accuracy\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
