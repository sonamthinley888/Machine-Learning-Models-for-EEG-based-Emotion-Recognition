{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b91aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, Conv2d,MaxPool1d, MaxPool2d, Module, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5dee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cz_eeg_data_1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cz_eeg_data_2.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cz_eeg_data_3.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cz_eeg_data_4.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cz_eeg_data_5.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>cz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  session subject  emotion\n",
       "0  cz_eeg_data_1.csv        1      cz        1\n",
       "1  cz_eeg_data_2.csv        1      cz        2\n",
       "2  cz_eeg_data_3.csv        1      cz        3\n",
       "3  cz_eeg_data_4.csv        1      cz        0\n",
       "4  cz_eeg_data_5.csv        1      cz        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_csv = pd.read_csv(r\"C:\\Users\\sonam\\University of Canberra\\4th Semester\\Capstone\\Models\\Session_1_labels.csv\")\n",
    "master_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d84ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 360/360 [05:20<00:00,  1.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_path = os.path.join(cwd,\"session_1_all_200\")\n",
    "\n",
    "eeg_data=[]\n",
    "for filename in tqdm(master_csv['filename']):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop the first row (column headers)\n",
    "    file = file.iloc[1:] \n",
    "    \n",
    "    # Drop rows below row 9600\n",
    "    file = file.iloc[:6002]\n",
    "    \n",
    "    file = file.astype('float32')\n",
    "    eeg_values = file.drop(columns=['time']).values  # Assuming 'time' column is not needed\n",
    "    \n",
    "    # Transpose the EEG data\n",
    "    eeg_values= eeg_values.T\n",
    "    \n",
    "#     # Calculate mean and standard deviation for Z-score normalization\n",
    "#     mean = np.mean(eeg_values, axis=0)\n",
    "#     std_dev = np.std(eeg_values, axis=0)\n",
    "    \n",
    "#     # Apply Z-score normalization\n",
    "#     eeg_values_normalized = (eeg_values - mean) / std_dev\n",
    "    \n",
    "    eeg_data.append(eeg_values)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "eeg_numpy = np.array(eeg_data)\n",
    "eeg_numpy.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8fca2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8298626e+07,  1.3113022e+07,  1.2934208e+07, ...,\n",
       "         -7.7784060e+06, -1.3977289e+07, -1.7225742e+07],\n",
       "        [ 1.9699336e+07,  1.3023615e+07,  2.1100044e+07, ...,\n",
       "         -1.1712313e+07, -1.8119812e+07, -1.1950731e+07],\n",
       "        [ 1.6123056e+07,  1.2725592e+07,  1.7762184e+07, ...,\n",
       "         -3.1501054e+07, -3.5375360e+07, -3.0547380e+07],\n",
       "        ...,\n",
       "        [ 2.0742416e+07,  2.4825334e+07,  3.6150216e+07, ...,\n",
       "         -2.5898218e+07, -1.7911196e+07, -1.4126301e+07],\n",
       "        [ 2.2798776e+07,  2.6345252e+07,  3.4958124e+07, ...,\n",
       "         -1.4543533e+07, -4.6491625e+06, -9.2387200e+05],\n",
       "        [ 3.3259392e+07,  3.9786104e+07,  5.0812956e+07, ...,\n",
       "         -2.3096800e+07, -1.2308359e+07, -1.0937452e+07]],\n",
       "\n",
       "       [[-3.8146972e+06, -2.1159650e+06, -1.7225742e+07, ...,\n",
       "         -2.6166440e+07, -3.0547380e+07, -2.3365020e+07],\n",
       "        [ 1.8477440e+06, -5.0663947e+05, -1.2397766e+07, ...,\n",
       "         -1.8745660e+07, -2.5302172e+07, -2.2500754e+07],\n",
       "        [ 8.5234640e+06,  3.2782553e+05, -1.6987324e+06, ...,\n",
       "          1.2874603e+07,  1.7613172e+07,  2.4050474e+07],\n",
       "        ...,\n",
       "        [ 2.1487474e+07,  2.1517276e+07,  2.1785498e+07, ...,\n",
       "         -1.7523766e+07, -1.5228987e+07, -1.2189150e+07],\n",
       "        [ 2.5629998e+07,  2.3663044e+07,  2.2411346e+07, ...,\n",
       "         -2.5331974e+07, -2.3066998e+07, -2.7626752e+07],\n",
       "        [ 9.0897080e+06,  5.5134295e+06,  2.9206275e+06, ...,\n",
       "         -2.7894974e+07, -2.5898218e+07, -3.3169982e+07]],\n",
       "\n",
       "       [[-2.9504300e+06, -1.1265278e+07, -1.1563301e+07, ...,\n",
       "         -1.4781952e+07, -2.9206275e+06, -1.1771917e+07],\n",
       "        [-1.3589859e+07, -2.5421380e+07, -2.5689602e+07, ...,\n",
       "         -6.0200690e+06,  5.5730345e+06, -5.9604644e+05],\n",
       "        [-2.0474196e+07, -3.2633544e+07, -3.5703184e+07, ...,\n",
       "         -1.2755394e+07,  5.9604645e+04, -5.6624415e+06],\n",
       "        ...,\n",
       "        [ 2.7060508e+07,  2.5212764e+07,  1.7017126e+07, ...,\n",
       "         -1.0013580e+07, -8.0466270e+06, -8.7916850e+06],\n",
       "        [ 2.4825334e+07,  2.3514032e+07,  1.4334917e+07, ...,\n",
       "         -9.6261500e+06, -6.3776970e+06, -8.4638600e+06],\n",
       "        [ 3.6150216e+07,  3.3438206e+07,  2.4557114e+07, ...,\n",
       "          8.3446500e+05,  5.0663950e+06,  8.9406969e+05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.0769576e+07,  3.3378602e+07,  4.1782856e+07, ...,\n",
       "         -1.1861324e+07,  4.8607588e+07,  8.3446500e+05],\n",
       "        [ 3.7938356e+07,  2.8997660e+07,  3.6060812e+07, ...,\n",
       "         -3.2901764e+07,  4.1812660e+07, -1.9222498e+07],\n",
       "        [ 3.1679868e+07,  2.5868416e+07,  3.0636788e+07, ...,\n",
       "         -4.5418740e+07,  2.4408102e+07, -3.4511088e+07],\n",
       "        ...,\n",
       "        [-3.3676625e+06, -7.7486038e+05, -2.8312208e+06, ...,\n",
       "         -4.7326088e+07,  7.5697900e+06, -3.1948090e+07],\n",
       "        [-1.4394522e+07, -1.1771917e+07, -1.6480684e+07, ...,\n",
       "         -6.3300132e+07,  3.5762788e+05, -4.5299532e+07],\n",
       "        [-1.3351440e+07, -1.2010336e+07, -1.5556812e+07, ...,\n",
       "         -6.3002108e+07, -1.4901161e+06, -4.2647124e+07]],\n",
       "\n",
       "       [[-6.8485736e+07, -4.6640632e+07, -6.0111284e+07, ...,\n",
       "         -3.6865472e+07, -2.8163194e+07, -1.1742115e+07],\n",
       "        [-6.4343216e+07, -3.9488076e+07, -5.4687264e+07, ...,\n",
       "         -3.6031004e+07, -2.7775764e+07, -1.4305115e+07],\n",
       "        [-4.9918892e+07, -2.7954578e+07, -4.0590764e+07, ...,\n",
       "         -3.6299228e+07, -3.1471252e+07, -1.6957522e+07],\n",
       "        ...,\n",
       "        [-9.7155570e+06, -1.7285348e+06, -6.0498715e+06, ...,\n",
       "         -9.9539760e+06, -2.3990870e+07, -7.6591970e+06],\n",
       "        [-1.2278557e+07, -1.6987324e+06, -1.0609627e+07, ...,\n",
       "         -7.8380110e+06, -2.0027160e+07, -3.9041042e+06],\n",
       "        [-1.1444092e+07, -2.7120112e+06, -8.8512900e+06, ...,\n",
       "         -6.8843365e+06, -2.0414590e+07, -3.8444995e+06]],\n",
       "\n",
       "       [[-4.0501360e+07, -3.2722950e+07, -3.6686660e+07, ...,\n",
       "         -2.8908252e+07,  7.4505805e+06, -1.1861324e+07],\n",
       "        [-4.2974948e+07, -3.1441450e+07, -4.2945144e+07, ...,\n",
       "         -3.3915044e+07,  3.4570695e+06, -1.9788742e+07],\n",
       "        [-4.1127204e+07, -2.8371810e+07, -3.3497810e+07, ...,\n",
       "         -2.9385090e+07,  1.9669532e+06, -2.0623208e+07],\n",
       "        ...,\n",
       "        [-1.9967556e+07, -1.3768673e+07, -2.2828578e+07, ...,\n",
       "         -1.3798475e+07, -6.3776970e+06, -1.0013580e+07],\n",
       "        [-3.0219554e+07, -2.1874904e+07, -3.0130148e+07, ...,\n",
       "         -2.0891428e+07, -9.4175340e+06, -1.4156103e+07],\n",
       "        [-3.0130148e+07, -2.2143126e+07, -3.1173230e+07, ...,\n",
       "         -2.0027160e+07, -9.8943710e+06, -1.2338161e+07]]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45a177b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 62, 6002)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d298ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 2 0 0 1 0 1 2 1 1 1 2 3 2 2 3 3 0 3 0 3 1 2 3 0 2 0 0 1 0 1 2 1 1\n",
      " 1 2 3 2 2 3 3 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "# defining the target\n",
    "label_emotion = master_csv['emotion'].values\n",
    "print(label_emotion[:48])  # Display the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a8ed5147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((270, 62, 6002), (270,)), ((90, 62, 6002), (90,)))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(eeg_numpy, label_emotion, test_size = 0.25, random_state = 13, stratify=label_emotion)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d56606ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "# Reshape training data\n",
    "# train_x = train_x.reshape(270, 1, 6002, 62)  # Adding a single channel (assuming grayscale)\n",
    "train_x = torch.from_numpy(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "081b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6ea0f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([270, 62, 6002]), torch.Size([270]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f9ee06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data\n",
    "# val_x = val_x.reshape(90, 1, 6002, 62)  # Adding a single channel (assuming grayscale)\n",
    "val_x = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "06d69a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 62, 6002]), torch.Size([90]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "92bedaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1d_layers = Sequential(\n",
    "            Conv1d(62, 4, kernel_size=3, stride=1, padding=1),  \n",
    "            BatchNorm1d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool1d(kernel_size=2, stride=2),\n",
    "            Conv1d(4, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm1d(8),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Calculate the number of features after convolutional layers\n",
    "        self.num_features = self._calculate_num_features((62, 6002))\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(self.num_features, 64),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def _calculate_num_features(self, input_dim):\n",
    "        input_tensor = torch.zeros(1, *input_dim)\n",
    "        conv_output = self.conv1d_layers(input_tensor)\n",
    "        num_features = conv_output.view(1, -1).size(1)\n",
    "        return num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2e923a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1d_layers): Sequential(\n",
      "    (0): Conv1d(62, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=12000, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "#if torch.cuda.is_available():\n",
    "device='cpu'\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# batch size of the model\n",
    "batch_size = 200\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e470b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 1.414980173110962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 2 \t training loss: \t 1.351163387298584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 3 \t training loss: \t 1.3139565587043762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 4 \t training loss: \t 1.3158336281776428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 5 \t training loss: \t 1.2819322347640991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 6 \t training loss: \t 1.2915798425674438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 7 \t training loss: \t 1.1775823831558228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 8 \t training loss: \t 1.2505672574043274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 9 \t training loss: \t 1.2482749223709106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 10 \t training loss: \t 1.1458349823951721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 11 \t training loss: \t 1.0985062420368195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 12 \t training loss: \t 1.2066644430160522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 13 \t training loss: \t 1.0954405963420868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 14 \t training loss: \t 1.181406855583191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 15 \t training loss: \t 1.1324608325958252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 16 \t training loss: \t 1.0962232947349548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 17 \t training loss: \t 1.124180257320404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 18 \t training loss: \t 0.9579303562641144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 19 \t training loss: \t 0.9406066834926605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 20 \t training loss: \t 0.9266426265239716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 21 \t training loss: \t 0.8701490461826324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 22 \t training loss: \t 0.8422550857067108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 23 \t training loss: \t 0.9138989448547363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 24 \t training loss: \t 0.8488000929355621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 25 \t training loss: \t 0.9241786897182465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 26 \t training loss: \t 0.8263504803180695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 27 \t training loss: \t 0.8066553473472595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 28 \t training loss: \t 0.8137241899967194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 29 \t training loss: \t 0.6767475306987762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 30 \t training loss: \t 0.7267604470252991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        # Convert batch_y to Long data type\n",
    "        batch_y = batch_y.long()  # Convert to Long data type\n",
    "        \n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27b031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb708a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: \t 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    #if torch.cuda.is_available():\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x)\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0069c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
